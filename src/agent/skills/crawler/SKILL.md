
# 智能爬虫技能 (Crawler Skills)

本技能集提供了一套完整的网页数据采集解决方案，包含自动分析网页结构、生成抓取模板、以及基于模板的高效数据提取功能。底层结合了 Puppeteer（动态渲染）和 Python BeautifulSoup（静态解析），并利用 LLM 增强了选择器识别和数据分类能力。

## 技能列表

### 1. 智能爬虫分析 (`crawler.analyze`)

分析目标网页的结构，自动推荐适合抓取数据的 CSS 选择器配置。

- **参数**:
    - `url` (string, 必填): 目标网页的完整 URL (需以 http:// 或 https:// 开头)。
    - `description` (string, 可选): 对想要提取内容的自然语言描述，帮助 AI 更精准地定位数据区域。

- **功能**:
    - 自动识别网页类型（静态/动态）。
    - 智能分析列表容器和字段选择器（标题、链接、日期等）。
    - 生成抓取模板的预览和置信度评分。

### 2. 爬虫数据提取 (`crawler.extract`)

根据模板或自动分析的结果，从网页中批量提取结构化数据。

- **参数**:
    - `url` (string, 必填): 目标网页的完整 URL。
    - `templateId` (string, 可选): 已保存的抓取模板 ID。如果不提供，系统将先执行自动分析。
    - `saveTemplate` (boolean, 可选): 是否将本次自动分析生成的规则保存为新模板。
    - `templateName` (string, 可选): 保存模板时的名称（仅在 `saveTemplate=true` 时有效）。

- **功能**:
    - **混合引擎支持**:
        - **静态引擎**: 基于 Python Requests + BeautifulSoup，速度快，适合传统网页。
        - **动态引擎**: 基于 Puppeteer，自动处理 JS 渲染、Cookies 注入和反爬策略（如湖北省站点）。
    - **智能分类**: 提取后利用 LLM 对数据进行自动分类（如“政策”、“解读”、“新闻”等）。
    - **分页抓取**: 支持配置分页规则，自动遍历多页数据。
    - **可视化**: 返回 HTML 格式的预览表格。

## 系统集成

### 配置文件
核心配置位于 `src/agent/skills/crawler/provinces.config.ts`，支持为特定站点配置：
- **Cookies**: 预置用户凭据以绕过登录或 WAF。
- **Headers**: 自定义 Referer 或 User-Agent。
- **动态渲染**: 强制开启 Puppeteer 渲染。

### 扩展开发
- **TypeScript 层**: 定义技能接口与流程控制 (`index.ts`)。
- **Python 引擎**: 负责高性能的 HTML 解析与数据清洗 (`engine.py`)。
- **动态引擎**: 处理浏览器自动化交互 (`dynamic_engine.ts`)。

## 使用示例

### 场景一：分析并抓取新站点
用户输入一个未知的政策列表页面 URL，不指定模板 ID。
1. 系统调用 `crawler.analyze` 分析页面结构。
2. 自动生成包含“标题”、“链接”、“发布日期”的选择器。
3. 执行抓取并返回预览数据。
4. (可选) 用户确认无误后，设置 `saveTemplate=true` 保存规则。

### 场景二：使用已有模板抓取
用户指定 `url` 和 `templateId`。
1. 系统加载对应 ID 的模板配置（包含选择器、分页设置等）。
2. 根据配置自动判断是否启用动态引擎。
3. 批量提取数据并进行 AI 分类。
4. 结果自动入库。
